# Exam_Score_ML_Project

# Project Documentation
Starting with the work on the final project i had a look at the requirements on the student portal on Ironhack and created a Kanban board on Trello in order to make sure not to forget any steps.
After selecting a Dataset from kaggle which i found interesting, seemed fitting for the application of a machine learning model and met the dataset size requirements i downloaded it and loaded it into a jupyter notebook. After having a first glance at the dataset in terms of NaN-values and categorical and numericla columns i thought about the necessary steps to clean and wrangle the dataset for it to be ready for me to start with fitting the machine learning models.

After checking for the amount of NaN-values and discovering that they were only around 1% of the dataset, i felt comfortable to drop them without affecting the size of the dataset in a critical way. Having dealt with the NaN-values i carried on with transforming all the categorical columns into numerical ones. These were mainly binomial columns or columns containing 3 entry types. 

Following this step i ran hypothesis test on the transformed columns to determine whether or not they were statistically significant. For the binomial columns i ran a t-test and for the columns with multiple entries i ran an ANOVA test. Both at an alpha-significance-level of 0.05%. The result of this hypothesis test was that i found 2 out of the 13 tested columns not to be statistically significant, so i dropped those two columns out of the dataset in order to have the best conditions for a good performing machine learning model. 

After having set the foundations i started fitting and evauluating different machine learning models. I quickly found the linear regression model to be the best performing. I did find however find a bit too weak correlation between the feature columns and the target column in order to safely say that a linear regression truly would be the optimal model. To solve this problem in tried my luck with hyperparameter tuning an cross validations. This measure did significantly improve the performances of the Randomforrest- and GradientBoostingRegressor, but sadly they did not outperform the LinearRegression model. During further investigation of my data i discovered a slight right skew in my data. I saw this as a reason for why the R2 value of my machine learnings models wouldnt improve above a certain threshold. In order to resolve this issue i used the PowerTransformer to transform my data and refit and reevaluate my models. After struggling with this method for a long time i came to the conclusion that this method also didnt enhance the model performance on my dataset.

Having settled for the best performing model. I could focus on the creation of the presentation and could also start to think about how one could apply to machine learnig model in the context of my business case. 
